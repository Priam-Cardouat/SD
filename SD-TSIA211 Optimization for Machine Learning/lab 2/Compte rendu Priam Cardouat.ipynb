{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 : Séparateurs à Vaste Marge\n",
    "\n",
    "## 1 Données\n",
    "\n",
    "Nous utiliserons la base de données breastcancer et utiliser la fonction fournie.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def load_breastcancer(filename):\n",
    "    \"\"\"\n",
    "    Cette fonction lit le fichier filename, par exemple\n",
    "    filename = 'wdbc_M1_B0.data'\n",
    "    Elle retourne \n",
    "    X : une matrice de caracteristiques\n",
    "    y : un vecteur des classes tel que si y[i] = 1, la tumeur est maligne\n",
    "        et si y[i] = -1, la tumeur est benigne\n",
    "\n",
    "    Pour plus d'infos sur la base de donnees,\n",
    "    https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Prognostic%29\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "\n",
    "    # la colonne 0 ne nous interesse pas ici\n",
    "    y = data[:, 1] * 2 - 1\n",
    "    X = data[:, 2:]\n",
    "\n",
    "    # Standardisation de la matrice\n",
    "    X = X - np.mean(X, axis=0)\n",
    "    X = X / np.std(X, axis=0)\n",
    "\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=load_breastcancer('wdbcM1B0.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Méthode du sous-gradient\n",
    "\n",
    "### Question 2.1 \n",
    "\n",
    "Nous avons le problème suivant :\n",
    "\n",
    "$$min_{v \\in \\mathbb{R}^{m}, a \\in \\mathbb{R}, \\xi \\in \\mathbb{R}^{n}} \\frac{1}{2} \\sum_{j=1}^{m} v_{j}^{2} + c \\sum_{i=1}^{n} \\xi_{i}$$\n",
    "$$\\xi_{i} \\ge 0 ,\\; \\forall i \\in \\{ 1,...,n \\}$$\n",
    "$$\\xi_{i} \\ge 1 - y_{i}(x_{i}^{T}v + a), \\; \\forall i \\in \\{ 1,...,n \\}$$\n",
    "\n",
    "où $c=1$.\n",
    "\n",
    "Notons $f(v,a,\\xi) = \\frac{1}{2} \\sum_{j=1}^{m} v_{j}^{2} + c \\sum_{i=1}^{n} \\xi_{i}$ définie sur $D_{f}=\\{ \\xi : \\xi_{i} \\ge 0 ,\\xi_{i} \\ge 1 - y_{i}(x_{i}^{T}v + a), \\; \\forall i \\in \\{ 1,...,n \\} \\}$. $f(v,a,.)$ est croissante sur $D_{f}$. \n",
    "\n",
    "Notons $\\xi_{min} = (max(0,1 - y_{i}(x_{i}^{T}v + a))_{1 \\le i \\le n}$. On a $f(v,a,\\xi) \\ge f(v,a,\\xi_{min})$ par croissance de $f(v,a,.)$.\n",
    "\n",
    "Donc $min_{v \\in \\mathbb{R}^{m}, a \\in \\mathbb{R}, \\xi \\in \\mathbb{R}^{n}} f(v,a,\\xi) \\ge min_{v \\in \\mathbb{R}^{m}, a \\in \\mathbb{R}, \\xi \\in \\mathbb{R}^{n}} f(v,a,\\xi_{min}) = min_{v \\in \\mathbb{R}^{m}, a \\in \\mathbb{R}} f(v,a,\\xi_{min}) \\qquad (1)$\n",
    "\n",
    "Par ailleurs, pour toute fonction $g : A \\times B \\rightarrow \\mathbb{R}$, $min_{a,b} g(a,b) \\le min_{a} g(a,\\beta) \\; \\forall \\beta \\in B$. En prenant $g=f$, $A=\\mathbb{R}^{m} \\times \\mathbb{R}$ et $B=\\mathbb{R}^{n}$ :\n",
    "\n",
    "$$min_{v \\in \\mathbb{R}^{m}, a \\in \\mathbb{R}, \\xi \\in \\mathbb{R}^{n}} f(v,a,\\xi) \\le min_{v \\in \\mathbb{R}^{m}, a \\in \\mathbb{R}, \\xi \\in \\mathbb{R}^{n}} f(v,a,\\xi_{min}) = min_{v \\in \\mathbb{R}^{m}, a \\in \\mathbb{R}} f(v,a,\\xi_{min}) \\qquad (2)$$\n",
    "\n",
    "Ainsi, d'après (1) et (2), $min_{v \\in \\mathbb{R}^{m}, a \\in \\mathbb{R}, \\xi \\in \\mathbb{R}^{n}} f(v,a,\\xi) = min_{v \\in \\mathbb{R}^{m}, a \\in \\mathbb{R}, \\xi \\in \\mathbb{R}^{n}} f(v,a,\\xi_{min}) = min_{v \\in \\mathbb{R}^{m}, a \\in \\mathbb{R}} f(v,a,\\xi_{min})$ et donc les deux problèmes sont équivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def h(z):\n",
    "    return np.maximum(np.zeros(len(z)),1-z)\n",
    "\n",
    "z=np.arange(-8,12,0.1)\n",
    "plt.figure()\n",
    "plt.plot(z,h(z),label='h(z)',color='red')\n",
    "plt.plot([-8,12], [-0.2,-.2], color = 'blue', label = \"sub_diff(h, 1)\")\n",
    "plt.plot([-8,12], [8.8, -11.2], color = 'blue')\n",
    "plt.plot([-8,12], [4.3, -5.7], color = 'blue')\n",
    "plt.plot([-8,12], [9*3/4-0.2,-11*3/4 -0.2], color = 'blue')\n",
    "plt.plot([-8,12], [9/4-0.2,-11/4 -0.2], color = 'blue')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h est différentiable partout sauf en 1 et on a : $\\forall z \\in \\mathbb{b}, z \\neq 1, \\partial h(z) = \\frac{\\partial h(z)}{\\partial z} = sgn(1-z)$. Pour $z=1$, on constate que toutes les pentes entre -1 et 1 conviennent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons N tel que  $N(v,a)=\\frac{1}{2} ||v||^{2} = \\frac{1}{2} \\sum_{i=1}^{m} v_{i}^{2}$. N est bien séparable (et convexe).\n",
    "\n",
    "Définissons H tel que $H(z) = \\sum_{i=1}^{n} h(z_{i})$. H est de même séparable (convexe et différentiable également).\n",
    "\n",
    "Enfin définissons M tel que \n",
    "$M= \n",
    "\\begin{pmatrix}\n",
    "y_{1} & &0 \\\\\n",
    "& \\ddots & \\\\\n",
    "0 & & y_{n}\n",
    "\\end{pmatrix} \n",
    "\\times \n",
    "\\begin{pmatrix}\n",
    "X, & \\begin{pmatrix} 1\\\\ \\vdots \\\\ 1 \\end{pmatrix} \\\\\n",
    "\\end{pmatrix}$\n",
    " M est un opérateur linéaire et on a : $M(v,a)=\\begin{pmatrix} y_{1}(x_{1}^{T}v+a) \\\\ \\vdots \\\\ y_{n}(x_{n}^{T}v+a) \\end{pmatrix}$\n",
    " \n",
    " M est bien une application linéaire.\n",
    " \n",
    "Ainsi, on a bien $f(v,a)=N(v, a) +cH(M(v, a))$.\n",
    "\n",
    "D'après la proposition 2.4.2 du cours, les conditions étant réunies, on a :\n",
    "\n",
    "$$\\partial f(v,a) = \\partial N(v,a) + c M^{T} \\partial H(M(v,a)) $$\n",
    "\n",
    "N étant différentiable, on a $\\partial N(v,a) = \\{ (\\nabla N(v), \\nabla N(a)) \\}$, i.e. $\\partial N(v,a) = \\{ (v,0) \\}$. \n",
    "\n",
    "Par ailleurs, H étant séparable, on a $\\partial H(z) = \\partial h(z_{1}) \\times ... \\times \\partial h(z_{n})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.4 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=1\n",
    "n=len(Y)\n",
    "Mat=np.diag(Y) @ np.concatenate((X,np.ones((n,1))),axis=1)\n",
    "\n",
    "def N(va):\n",
    "    return 0.5*np.sum(va[:-1]**2)\n",
    "\n",
    "def H(z):\n",
    "    return np.sum(h(z))\n",
    "\n",
    "def M(va):\n",
    "    return Mat @ (va)\n",
    "    \n",
    "def f(va):\n",
    "    return N(va)+c*H(M(va))\n",
    "\n",
    "def d_N(va):\n",
    "    va[len(va)-1]=0\n",
    "    return va\n",
    "\n",
    "def d_H(z):\n",
    "    result=[]\n",
    "    m=len(z)\n",
    "    for i in range(m):\n",
    "        if z[i]<1:\n",
    "            result.append((-1))\n",
    "        if z[i]>1:\n",
    "            result.append((1))\n",
    "        if z[i]==1:\n",
    "            result.append(random.randrange(-1,0)) #We select a subgradient\n",
    "    return result\n",
    "\n",
    "\n",
    "def d_f(va):\n",
    "    #return an element of the subgradient\n",
    "    return [d_N(va)[i]+(np.transpose(c*Mat) @ d_H(M(va)))[i] for i in range(len(d_N(va)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimiseur obtenu= [-0.2563311   0.13318085 -0.24154662 -0.1370914  -0.09593255 -0.59240781\n",
      "  0.22236272  0.30909915 -0.07430238 -0.1197459   0.23308399 -0.30393255\n",
      " -0.09976162 -0.02486787  0.01301957 -0.14483386 -0.02199856 -0.20006718\n",
      " -0.20131629  0.11058338  0.14314164  0.20896945  0.01168679  0.00263704\n",
      "  0.17733056 -0.67268217 -0.00222325 -0.19902352  0.16136092 -0.18113663\n",
      "  0.115     ]\n",
      "\n",
      "Minimum= 1018.2140.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def subgradient_method(va0,nombre_iter):\n",
    "    vak=va0\n",
    "    list_gamma=[]\n",
    "    list_x=[vak]\n",
    "    res=[0]*len(vak)\n",
    "    for k in range(nombre_iter):\n",
    "        gk=d_f(vak)\n",
    "        gammak=1/(k+1)\n",
    "        list_gamma.append(gammak)\n",
    "        temp=[i*gammak for i in gk]\n",
    "        for i in range(len(vak)):\n",
    "            vak[i]=vak[i]-temp[i]\n",
    "        list_x.append(vak)\n",
    "        for i in range(len(res)):\n",
    "            res[i]=np.multiply(list_gamma,np.array(list_x[:-1])[:,i]).sum(0)/np.sum(list_gamma)\n",
    "    return np.array(res)\n",
    "\n",
    "minimiseur=subgradient_method([0]*31,1000)\n",
    "\n",
    "print('Minimiseur obtenu=', minimiseur)\n",
    "print('\\nMinimum= {:.4f}.\\n'.format(f(minimiseur)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode du sous-gradient stochastique\n",
    "\n",
    "### Question 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a :\n",
    "    \n",
    "$$\\mathbb{E}[f_{I}(v,a)]=\\frac{1}{2} \\sum_{j=1}^{m} v_{j}^{2} + c n \\mathbb{E}[max(0,y_{I}(x_{I}^{T}v+a))]  \\qquad par linéarité$$\n",
    "\n",
    "Puis : \n",
    "\n",
    "$$\\mathbb{E}[max(0,y_{I}(x_{I}^{T}v+a))]= \\sum_{i=1}^{n} \\mathbb{P}(I = i) max(0,y_{i}(x_{i}^{T}v+a)) = \\frac{1}{n} \\sum_{i=1}^{n}max(0,y_{i}(x_{i}^{T}v+a))$$\n",
    "\n",
    "Donc on a bien $$\\mathbb{E}[f_{I}(v,a)]=f(v,a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2\n",
    "\n",
    "Posons $\\tilde{M_{i}}=y_{i}(x_{i}^{T},1)$ opérateur linéaire. On a : $\\tilde{M_{i}}(v,a)=y_{i}(x_{i}^{T}v+a)$\n",
    "\n",
    "On a donc $f_{i}(v,a)=N(v,a) + c n h(\\tilde{M_{i}}(v,a))$.\n",
    "\n",
    "Toujours selon la propriété 2.4.2 du cours, nous avons :\n",
    "\n",
    "$$\\partial f_{i}(v,a) = \\partial N(v,a) + cn \\tilde{M_{i}}^{T} \\partial h(\\tilde{M_{i}}(v,a))$$\n",
    "\n",
    "et donc :\n",
    "\n",
    "$$\\partial f_{i}(v,a) = \n",
    "\\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        (v,0) - cn\\tilde{M_{i}}^{T} & \\mbox{si } \\tilde{M_{i}}(v,a) < 1 \\\\\n",
    "        (v,0) + \\alpha cn\\tilde{M_{i}}^{T}, \\, \\alpha \\in [-1,0] & \\mbox{si } \\tilde{M_{i}}(v,a) = 1 \\\\\n",
    "        (v,0) & \\mbox{si } \\tilde{M_{i}}(v,a) > 1 \\\\\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimiseur obtenu= [  81.08788803 -166.67497211   84.04802072   74.88354104  173.34160931\n",
      "  117.56134646   84.8694345   110.23769798  -33.91152798   80.93737663\n",
      "   97.15772791   42.42439143   83.27552667   68.15685339   95.57959444\n",
      "   39.75960435   43.68145145  113.91564196   51.87390324   49.66290064\n",
      "   90.39176264 -110.44103393   84.85877802   78.58894042  164.70860832\n",
      "   68.55675419   79.0145516   138.55027997    4.54540611   63.90496041\n",
      "    0.        ]\n"
     ]
    }
   ],
   "source": [
    "def d_h_M_tilde(va,i):\n",
    "    if Mat[i,:] @ va <1:\n",
    "        return [(-c)*Mat.shape[0]*elem for elem in Mat[i,:]]\n",
    "    if Mat[i,:] @ va == 1:\n",
    "        return [np.randrange(-1,0)*c*Mat.shape[0]*elem for elem in Mat[i,:]]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def d_fi(va,i):\n",
    "    if d_h_M_tilde(va,i)==0:\n",
    "        return d_N(va)\n",
    "    else:\n",
    "        return d_N(va)+np.array(d_h_M_tilde(va,i))\n",
    "\n",
    "def sous_grad_stoch(va0,N):\n",
    "    n=Mat.shape[0]\n",
    "    vak=va0\n",
    "    gamma_sum=0\n",
    "    ponder=0\n",
    "    for k in range(N):\n",
    "        gammak=1/(k+1)\n",
    "        gamma_sum+=gammak\n",
    "        i=random.randint(1,n)\n",
    "        gk=d_fi(vak,i)\n",
    "        ponder+=gammak*vak\n",
    "        vak-=gammak*gk\n",
    "    return (1/gamma_sum)*ponder\n",
    "        \n",
    "minim=sous_grad_stoch(np.zeros(31),200)\n",
    "print('Minimiseur obtenu=', minim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum associé au problème 2 = 185525.4649753602\n"
     ]
    }
   ],
   "source": [
    "minimum=f(minim)\n",
    "print('Minimum associé au problème 2 =', minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le minimum et le minimiseur peuvent être susceptible de varier dans la mesure où nous prenons un élément aléatoire de la sous-différentielle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode du lagrangien augmenté\n",
    "\n",
    "### Question 4.1\n",
    "\n",
    "Pour le problème (1), nous avons les conditions : $g(v,a,\\xi)=(\\xi_{1},...,\\xi_{n},1-\\xi_{1}-y_{1}(x_{1}^{T}v+a), 1-\\xi_{n}-y_{n}(x_{n}^{T}v+a)) \\leq 0$\n",
    "\n",
    "Le lagrangien associé au problème (1) est donné par :\n",
    "\n",
    "$$L : \\mathbb{R}^{m} \\times \\mathbb{R} \\times \\mathbb{R}^{n} \\times \\mathbb{R}^{2n} \\rightarrow \\mathbb{R}$$\n",
    "\n",
    "$$(v,a,\\xi,\\phi) \\rightarrow f(v,a,\\xi) + <\\phi,g(v,a,\\xi)> -\\iota_{\\mathbb{R}^{2n}}(\\phi)$$\n",
    "\n",
    "C'est-à-dire :\n",
    "\n",
    "$$L(v,a,\\xi,\\phi)=\\frac{1}{2} \\sum_{j=1}^{m} v_{j}^{2} + c \\sum_{i=1}^{n} \\xi_{i} - \\sum_{i=1}^{n}\\phi_{i} \\xi_{i} + \\sum_{i=1}^{n}\\phi_{i+n}(1-\\xi_{i}-y_{i}(x_{i}^{T}v+a))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.2\n",
    "\n",
    "Fixons $\\phi$. Pour $x>-\\frac{\\phi}{\\rho}$, $g(x,\\phi)=\\frac{\\rho x^{2}}{2} + x \\phi$. Donc $g(.,\\phi)$ est dérivable sur $]-\\frac{\\phi}{\\rho}, \\infty[$ et $\\nabla_{x}g(x,\\phi)=\\rho x + \\phi$\n",
    "\n",
    "De même, sur $]-\\infty,-\\frac{\\phi}{\\rho}[$, $g(x,\\phi)=-\\frac{1}{2\\rho} \\phi^{2}$ et donc $\\nabla_{x}g(x,\\phi)=0$\n",
    "\n",
    "Par ailleurs, $lim_{x \\rightarrow -\\frac{\\phi}{\\rho}_{-}} \\nabla_{x}g(x,\\phi) = lim_{x \\rightarrow -\\frac{\\phi}{\\rho}_{+}} \\nabla_{x}g(x,\\phi) =0$. Donc $g(.,\\phi)$ est dérivable sur $\\mathbb{R}$ et on a :\n",
    "\n",
    "$$\\nabla_{x}g(x,\\phi)=\n",
    "\\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        0 & \\mbox{si } x \\leq -\\frac{\\phi}{\\rho} \\\\\n",
    "        \\rho x + \\phi & \\mbox{si } x>-\\frac{\\phi}{\\rho} \\\\\n",
    "    \\end{array}\n",
    "\\right.$$\n",
    "\n",
    "i.e : $$\\nabla_{x}g(x,\\phi)=\\rho max(0,x+\\frac{\\phi}{\\rho})$$\n",
    "\n",
    "De même, pour $g(x,.)$ on prolonge par continuité $\\nabla_{\\phi}g$ et on a :\n",
    "\n",
    "$$\\nabla_{\\phi}g(x,\\phi)=\n",
    "\\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        0 & \\mbox{si } \\phi \\geq -x\\rho \\\\\n",
    "        -\\frac{\\phi}{\\rho} & \\mbox{si } \\phi < -x\\rho \\\\\n",
    "    \\end{array}\n",
    "\\right.$$\n",
    "\n",
    "i.e. :\n",
    "$$\\nabla_{\\phi}g(x,\\phi)=max(-\\frac{\\phi}{\\rho},x)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.3\n",
    "\n",
    "La fonction $x \\longmapsto g(x,\\phi)$ pour $\\phi$ fixé a pour dérivée $\\nabla_{x}g(.,\\phi)$ qui est croissante d'après l'expression obtenue à la question précédente. Par conséquent, $x \\longmapsto g(x,\\phi)$ est convexe.\n",
    "\n",
    "De même $\\phi \\longmapsto g(x,\\phi)$ pour x fixé a pour dérivée $\\nabla_{\\phi}g(x,.)$ qui est décroissante d'après l'expression obtenue à la question précédente. Par conséquent, $\\phi \\longmapsto g(x,\\phi)$ est concave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.4\n",
    "\n",
    "Déterminons les expressions des gradients nécessaires. On a :\n",
    "\n",
    "$$\\nabla_{v}L(v,a,\\xi,\\phi_{k},\\psi_{k})=v- (\n",
    "\\begin{pmatrix}\n",
    "y_{1} & &0 \\\\\n",
    "& \\ddots & \\\\\n",
    "0 & & y_{n}\n",
    "\\end{pmatrix} \n",
    "\\times\n",
    "X)^{T}\n",
    "\\begin{pmatrix} \\nabla_{x}g(1-\\xi_{1}-y_{1}(x_{1}^{T}v+a),\\psi_{1})\\\\ \\vdots \\\\ \\nabla_{x}g(1-\\xi_{n}-y_{n}(x_{n}^{T}v+a),\\psi_{n})\n",
    "\\end{pmatrix} $$\n",
    "\n",
    "$$\\nabla_{a}L(v,a,\\xi,\\phi_{k},\\psi_{k})=-\\sum_{i=1}^{n} y_{i} \\nabla_{x}g(1-\\xi_{i}-y_{i}(x_{i}^{T}v+a),\\psi_{i})$$\n",
    "\n",
    "et \n",
    "\n",
    "$$\\nabla_{\\xi}L(v,a,\\xi,\\phi_{k},\\psi_{k})=\n",
    "\\begin{pmatrix} \n",
    "c-\\nabla_{x}g(-\\xi_{1},\\phi_{1})-\\nabla_{x}g(1-\\xi_{1}-y_{1}(x_{1}^{T}v+a),\\psi_{1})\\\\ \\vdots \\\\ c-\\nabla_{x}g(-\\xi_{n},\\phi_{n})-\\nabla_{x}g(1-\\xi_{n}-y_{n}(x_{n}^{T}v+a),\\psi_{n})\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho=2\n",
    "epsilon=1\n",
    "\n",
    "def g(x,phi):\n",
    "    return (-(phi**2)/(2*rho))+rho*(np.maximum(0,x+(phi/rho))**2)/rho\n",
    "\n",
    "def L_rho(v,a,xi,phi,psi):\n",
    "    return 0.5*np.sum(v**2)+c*np.sum(xi)+np.sum(g(-xi,phi))+np.sum(g(-xi+1-M(np.insert(v, len(v)-1, a, axis=0)),psi))\n",
    "    \n",
    "def nabla_x_g(x,phi):\n",
    "    return rho*np.maximum(0,x+(phi/rho))\n",
    "\n",
    "def gradient_lin(v0,a0,xi0,phi,psi):\n",
    "    vk=v0\n",
    "    ak=a0\n",
    "    xik=xi0\n",
    "    b=10\n",
    "    a=0.5\n",
    "    x = 1-xik-np.dot(np.diag(Y), np.dot(X, vk) + a)\n",
    "    grad_v=vk-np.dot(np.dot(np.diag(Y), X).T, nabla_x_g(x, psi))\n",
    "    grad_a=-np.sum(Y * nabla_x_g(x,psi))\n",
    "    grad_xi=c - nabla_x_g(-xik, phi) - nabla_x_g(x, psi)\n",
    "    while np.sum(grad_v**2)+grad_a**2+np.sum(grad_xi**2)>epsilon:\n",
    "        l=1\n",
    "        v_plus=vk-(b*(a**l))*grad_v\n",
    "        a_plus=ak-(b*(a**l))*grad_a\n",
    "        xi_plus=xik-(b*(a**l))*grad_xi\n",
    "        while L_rho(v_plus,a_plus,xi_plus,phi,psi)>L_rho(vk,ak,xik,phi,psi)+np.sum(grad_v*(v_plus-vk))+np.sum(grad_a*(a_plus-ak))+np.sum(grad_xi*(xi_plus-xik))+0.5*(b*(a**l))*(np.sum((v_plus-vk)**2)+np.sum((a_plus-ak)**2)+np.sum((xi_plus-xik)**2)):\n",
    "            l+=1\n",
    "        gammak=b*(a**l)\n",
    "        vk-=gammak*grad_v\n",
    "        ak-=gammak*grad_a\n",
    "        xi_plus=gammak*grad_xi\n",
    "        x = 1-xik-np.dot(np.diag(Y), np.dot(X, vk) + a)\n",
    "        grad_v=vk-np.dot(np.dot(np.diag(Y), X).T, nabla_x_g(x, psi))\n",
    "        grad_a=-np.sum(Y * nabla_x_g(x,psi))\n",
    "        grad_xi=c - nabla_x_g(-xik, phi) - nabla_x_g(x, psi)\n",
    "    return vk,ak,xik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nabla_phi_psi_L(v,a,xi,phi,psi):\n",
    "    nabla_phi=np.maximum(-(1/rho)*phi,-xi)\n",
    "    x = 1-xi-np.dot(np.diag(y), np.dot(X, v) + a)\n",
    "    nabla_psi=np.maximum(-(1/rho)*phi,x)\n",
    "    return nabla_phi,nabla_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_lagrangian(v,a,xi,phi,psi,N):\n",
    "    vk,ak,xik,psik,phik=v,a,xi,psi,phi\n",
    "    for i in range(N):\n",
    "        vk,ak,xik=gradient_lin(vk,ak,xik,phik,psik)\n",
    "        nabla_phi,nabla_psi=nabla_phi_psi_L(vk,ak,xik,phik,psik)\n",
    "        phik+=rho*nabla_phi\n",
    "        psik+=rho*nabla_psi\n",
    "    return vk,ak,xik,phik,psik\n",
    "\n",
    "augmented_lagrangian(np.zeros((30,)),0,np.zeros((569,)),np.zeros((569,)),np.zeros((569,)),2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Comparaison\n",
    "\n",
    "## Question 5.1\n",
    "\n",
    "Comparons les différents algorithmes utilisés. Pour cela, ce serait bien que la méthode du lagrangien augmenté se termine, 2000 itérations c'est peut-être beaucoup quand même, surtout si on fait de la recherche linéaire en plus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
